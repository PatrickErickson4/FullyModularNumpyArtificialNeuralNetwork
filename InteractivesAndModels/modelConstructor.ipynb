{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Model Constructor\n",
    "---\n",
    "The following is a python script for reproducing the MNIST model I used to classify my images.\n",
    "\n",
    "## **NOTE**: Due the the non-parallizeable nature of python, this runs extremely slowly. Set aside a couple of hours if you wish to create your own model with the following parameters.\n",
    "\n",
    "Run the code below to regenerate the same model I used in the drawing tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Dimensions:\n",
      "Train Set: (60000, 784)\n",
      "Train Labels: (60000, 10)\n",
      "Test Set: (10000, 784)\n",
      "Test Labels: (10000, 10)\n",
      "Starting model training. Epochs will periodically print between 10 and 20 minutes.\n",
      "loss for epoch:  1 : 2.2796016050843533\n",
      "loss for epoch:  2 : 0.6604765615479542\n",
      "loss for epoch:  3 : 0.4167719557732928\n",
      "loss for epoch:  4 : 0.3257775793987371\n",
      "loss for epoch:  5 : 0.26738986036664114\n",
      "loss for epoch:  6 : 0.22127803972857935\n",
      "loss for epoch:  7 : 0.19084752899748855\n",
      "loss for epoch:  8 : 0.1595542247352233\n",
      "loss for epoch:  9 : 0.1309223633227243\n",
      "loss for epoch:  10 : 0.1109718298406343\n",
      "loss for epoch:  11 : 0.09110099007333433\n",
      "loss for epoch:  12 : 0.07953411972331074\n",
      "\n",
      "Final Training Loss: 0.07175497542480534\n",
      "Training Acc: 97.88%\n",
      "\n",
      "Final Testing Loss: 0.1209791430887968\n",
      "Testing Acc: 96.45%\n",
      "Model saved as MNISTModel within the local directory.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "scripts_path = r\"../\"\n",
    "\n",
    "if scripts_path not in sys.path:\n",
    "    sys.path.append(scripts_path)\n",
    "\n",
    "from NeuralNetworkScripts.NeuralNetwork import NeuralNetwork\n",
    "from NeuralNetworkScripts.Layer import FullyConnectedLayer\n",
    "from NeuralNetworkScripts.DataHandler import DataHelper\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "np.random.seed(100) # unseeded for cv\n",
    "\n",
    "# Load the MNIST dataset and split labels into one-hot\n",
    "(digitsTrainSet, digitsTrainLabels), (digitsTestSet, digitsTestLabels) = mnist.load_data()\n",
    "\n",
    "order = [0,1,2,3,4,5,6,7,8,9]\n",
    "trainLabels,_ = DataHelper.toOneHot(digitsTrainLabels, order)\n",
    "testLabels,_ = DataHelper.toOneHot(digitsTestLabels, order)\n",
    "\n",
    "trainSet = digitsTrainSet.reshape(60000, 28*28) # stretch out to naively get 784 features\n",
    "testSet = digitsTestSet.reshape(10000, 28*28)\n",
    "\n",
    "print(\"Current Dimensions:\")\n",
    "print(\"Train Set:\", trainSet.shape)\n",
    "print(\"Train Labels:\", trainLabels.shape)\n",
    "print(\"Test Set:\", testSet.shape)\n",
    "print(\"Test Labels:\", testLabels.shape)\n",
    "\n",
    "#trainSet, trainLabels, testSet, testLabels = DataHelper.trainTestSplit(trainSet, trainLabels) # cross-validation used to find hyperparameters\n",
    "\n",
    "Standardizer = DataHelper.standardizer(trainSet)\n",
    "trainSet = DataHelper.standardizeCompute(trainSet,Standardizer)\n",
    "testSet = DataHelper.standardizeCompute(testSet,Standardizer)\n",
    "\n",
    "x = NeuralNetwork(\n",
    "                # NOTE: Best found hyperparams after cv\n",
    "                #inputDropout=x specified here\n",
    "                #batchSize=default 32 #batchTests\n",
    "                hidden2 = FullyConnectedLayer(numNodes=400,activation='ReLU',dropout=.05), \n",
    "                hidden3 = FullyConnectedLayer(numNodes=400,activation='ReLU',dropout=.05),\n",
    "                output = FullyConnectedLayer(numNodes=10,activation='softmax')\n",
    "                )\n",
    "\n",
    "# specify Adam and AdamW. weight decay means nothing if used with Adam\n",
    "print(\"Starting model training. Epochs will periodically print between 10 and 20 minutes.\")\n",
    "x.train(trainSet, trainLabels, epochs=12, learningRate=.001,loss='AdamW',weightDecay=.17) \n",
    "\n",
    "lossTraining, trainGuesses = x.test(trainSet, trainLabels)\n",
    "\n",
    "predictedTrain = np.argmax(trainGuesses, axis=1)\n",
    "trueTrain = np.argmax(trainLabels, axis=1)\n",
    "trainAccuracy = np.mean(predictedTrain == trueTrain) * 100\n",
    "\n",
    "print(\"\\nFinal Training Loss:\", lossTraining)\n",
    "print(\"Training Acc: {:.2f}%\".format(trainAccuracy))\n",
    "\n",
    "lossTesting, testGuesses = x.evaluate(testSet, testLabels)\n",
    "\n",
    "predictedTest = np.argmax(testGuesses, axis=1)\n",
    "trueTest = np.argmax(testLabels, axis=1)\n",
    "testAccuracy = np.mean(predictedTest == trueTest) * 100\n",
    "\n",
    "print(\"\\nFinal Testing Loss:\", lossTesting)\n",
    "print(\"Testing Acc: {:.2f}%\".format(testAccuracy))\n",
    "\n",
    "x.saveModel(\"MNISTModel\")\n",
    "print(\"Model saved as MNISTModel within the local directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code chunks show the model being reloaded and working to classify the same test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Testing Loss: 0.12116224664761685\n",
      "Testing Acc: 96.59%\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "savedModel = NeuralNetwork(model=\"MNISTModel\")\n",
    "lossSaved, guessesSaved = savedModel.evaluate(testSet, testLabels)\n",
    "\n",
    "predictedSaved = np.argmax(guessesSaved, axis=1)\n",
    "trueSaved = np.argmax(testLabels, axis=1)\n",
    "accuracySaved = np.mean(predictedSaved == trueSaved) * 100\n",
    "\n",
    "print(\"\\nFinal Testing Loss:\", lossSaved)\n",
    "print(\"Testing Acc: {:.2f}%\".format(accuracySaved))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
